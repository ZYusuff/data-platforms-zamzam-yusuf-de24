{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) What is Apache Kafka, and how does it work?\n",
    "\n",
    "Apache Kafka is a distributed event streaming platform used to handle real-time data. It helps systems send and receive messages efficiently, making it ideal for building data pipelines and streaming applications.\n",
    "\n",
    "Apache Kafka är en plattform för att hantera strömmande data i realtid. Tänk på det som ett system som gör det möjligt att skicka och ta emot meddelanden mellan olika applikationer snabbt och på ett pålitligt sätt.\n",
    "\n",
    "Om du har jobbat med Python och SQL, kan du tänka dig Kafka som en plats där du kan skicka och lagra data, ungefär som en databas, men med fokus på att hantera och bearbeta stora mängder data kontinuerligt och i realtid.\n",
    "\n",
    "Kafka är uppbyggt kring en topic, vilket är en slags kategori för data (som en tabell i SQL). När en applikation vill skicka data, skickar den det till en topic i Kafka. Sedan kan andra applikationer (konsumenter) läsa den datan när de behöver, som en sorts \"kö\" av meddelanden.\n",
    "\n",
    "Det som gör Kafka speciellt är att det kan hantera mycket stora mängder data och skala upp enkelt om du behöver mer kapacitet. Det är också byggt för att vara robust och pålitligt, vilket betyder att om något går fel kommer inte data gå förlorad.\n",
    "\n",
    "Så, även om du kanske inte är bekant med \"dataplattformar\", kan du tänka på Kafka som ett kraftfullt och flexibelt system för att hantera dataflöden mellan olika system, och det används mycket i moderna, realtidsbaserade applikationer och tjänster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) What is a Kafka topic?\n",
    "\n",
    "A Kafka topic is a category or stream where messages are stored and organized in Apache Kafka. Think of it as a virtual mailbox where producers send data and consumers read from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) How does the Kafka broker, cluster and partitions relate to each other?\n",
    "\n",
    "A Kafka broker is a server that stores and manages messages from topics and handles requests from producers and consumers. Multiple brokers work together to form a Kafka cluster, which ensures scalability and fault tolerance by distributing and replicating data. Each topic in Kafka is divided into partitions, which are spread across brokers to balance the load and maintain message order within each partition. This setup allows Kafka to handle large volumes of data efficiently while ensuring high availability and reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) What are Kafka producers and consumers and the publish-subscribe model?\n",
    "\n",
    "Kafka producers are applications that send messages (data) to Kafka topics. On the other hand, consumers are applications that read and process these messages from topics. Multiple producers and consumers can interact with the same topic simultaneously.\n",
    "\n",
    "Kafka follows the publish-subscribe model, where producers \"publish\" messages to topics, and consumers \"subscribe\" to those topics to receive the data. This decouples data producers and consumers, making Kafka highly scalable and ideal for real-time data streaming. Consumers can also join consumer groups to share the load and ensure that each message is processed only once across the group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) How does Kafka guarantee message ordering?\n",
    "\n",
    "\n",
    "Kafka guarantees message ordering within individual partitions of a topic. Messages in a partition are always appended in the order they are received, and Kafka assigns each message a unique, sequential offset. Consumers read messages from partitions in this offset order, ensuring they receive them in the correct sequence.\n",
    "\n",
    "To maintain ordering across multiple partitions, Kafka requires careful design. Producers can use keys when sending messages, which Kafka uses to consistently route all messages with the same key to the same partition, preserving their order. However, Kafka does not guarantee ordering across partitions—only within a single partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) What is key-based partitioning in Kafka?\n",
    "\n",
    "Key-based partitioning in Kafka assigns messages to specific partitions based on a key provided by the producer. Kafka uses a hash function to consistently route messages with the same key to the same partition. This ensures that related messages maintain their order and are grouped together for easier processing, which is essential for scenarios requiring data consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) How do you setup Kafka locally?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glossary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kafka - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "producer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consumer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "publish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subscribe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "publish-subscribe model\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source system\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "serialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deserialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pull model\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "push model\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "client\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "advertise\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ports mapping\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detached mode\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "docker exec -it\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
